# Прикладное использование — рецепты с копипастой

Этот файл — практические инструкции «что делать руками» для трёх задач: риски, сенсоры, A/B-тесты. Здесь минимум терминов и максимум конкретики с работающими примерами.

## Установка и настройка

**Шаг 1. Установите библиотеку:**
```bash
# В корне проекта ProbStates
python3 -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -e .
pip install matplotlib
```

**Шаг 2. Импорты для всех примеров:**
```python
import numpy as np
from probstates import ProbabilisticBit, PhaseState, PhaseRegister, set_phase_or_mode
from probstates.coherence import dephase, amp_damp
from probstates.entropy import shannon_entropy, kl_divergence, calculate_entropy
```
---

## Кейс 1: Управление рисками

**Задача:** Объединить несколько источников риска в общую оценку, учитывая что некоторые дублируют друг друга, а некоторые компенсируют.

### Конкретный пример: банк оценивает клиента

Представьте: банк «Надёжный» рассматривает заявку на кредит от Ивана Петрова. У банка есть 4 системы проверки:

**Система анти-фрода:** Проанализировала паспорт, номер телефона, IP-адрес. Выдала вероятность мошенничества 12% (p=0.12). Основание: необычный паттерн поведения — заявка подана ночью, IP из другого региона.

**Кредитное бюро:** Проверило кредитную историю в других банках. Показало 8% вероятности проблем (p=0.08). Основание: одна небольшая просрочка 2 года назад на 5 дней.

**Внутренняя скоринговая модель:** Обработала 200+ факторов — доходы, траты, социальные данные. Выдала 18% риска (p=0.18). Основание: доходы нестабильные, много трат на развлечения.

**Ручная проверка аналитика:** Сотрудник банка позвонил клиенту, проверил документы, оценил адекватность. Дал 15% риска (p=0.15). Основание: клиент отвечал уверенно, документы в порядке, но цель кредита изменилась во время разговора.

### Почему простое сложение не работает

Если банк просто сложит эти вероятности классическим способом, получится: P(любой риск) = 1 - (1-0.12)×(1-0.08)×(1-0.18)×(1-0.15) ≈ 45%. Это означает отказ практически каждому второму клиенту!

Но аналитики банка понимают: многие из этих сигналов связаны. Анти-фрод и скоринговая модель часто реагируют на одни и те же подозрительные паттерны поведения. А ручная проверка обычно **снижает** подозрения, найденные автоматикой, потому что живой человек может объяснить странности.

### Как мы это моделируем углами

**Дубли (угол 0°):** Анти-фрод (p=0.12) и скоринг (p=0.18) часто срабатывают на одно и то же — ночные заявки, нестабильные доходы, странные IP. Ставим им угол 0°, чтобы не удваивать одинаковые подозрения.

**Компенсация (угол 180°):** Ручная проверка (p=0.15) обычно работает «против» автоматики — если робот нашёл подозрения, человек может их опровергнуть. Ставим угол 180°.

**Независимость (промежуточный угол):** Кредитное бюро (p=0.08) работает с историческими данными, которые не зависят от текущего поведения. Ставим угол π/3 (60°).

### Рецепт (копируйте целиком):

```python
# БЛОК 1: Базовая оценка (простое сложение)
risk_sources = [0.12, 0.08, 0.18, 0.15]  # ваши вероятности рисков
print("Исходные риски:", risk_sources)

# Простое сложение на уровне 2
base_risk = ProbabilisticBit(risk_sources[0])
for p in risk_sources[1:]:
    base_risk = base_risk | ProbabilisticBit(p)
print("Базовый риск (простое сложение):", round(base_risk.probability, 4))

# БЛОК 2: Умное объединение с учётом дублей/конфликтов
# Углы по логике нашего банковского примера:
# Анти-фрод (0.12) и скоринг (0.18) = дубли = угол 0°
# Кредитное бюро (0.08) = независимо = угол π/3
# Ручная проверка (0.15) = компенсация = угол π
angles = [0.0, np.pi/3, 0.0, np.pi]  # [анти-фрод, кред.бюро, скоринг, ручная]
states = [PhaseState(p, angle) for p, angle in zip(risk_sources, angles)]

# Выберите режим склейки (попробуйте разные)
set_phase_or_mode('weight')  # робастный режим для продакшена
# set_phase_or_mode('norm')  # консервативный для регуляторики
# set_phase_or_mode('quant') # агрессивный для исследований

smart_risk = states[0]
for state in states[1:]:
    smart_risk = smart_risk | state

print("Умный риск (с учётом дублей):", round(smart_risk.probability, 4))

# БЛОК 3: Проверка на устойчивость к шумам
noisy_risk = smart_risk
noisy_risk = dephase(noisy_risk, sigma_phi=0.1)   # фазовый шум
noisy_risk = amp_damp(noisy_risk, alpha=0.2)      # затухание
print("Риск под шумом:", round(noisy_risk.probability, 4))

# БЛОК 4: Диагностика информативности
from probstates.entropy import calculate_entropy
h_base = calculate_entropy(base_risk)
h_smart = calculate_entropy(smart_risk)
print("Энтропия базового риска:", round(h_base, 3))
print("Энтропия умного риска:", round(h_smart, 3))
```

### Что получится в результате

**Простое сложение показало:** 45% риска — почти каждому второму клиенту отказ. Слишком жёстко!

**Умное объединение покажет:** примерно 25-30% риска. Почему меньше? Потому что учли дубли между анти-фродом и скорингом (они не удваиваются), а ручная проверка частично компенсировала автоматические подозрения.

**Проверка устойчивости:** Если умный риск сильно меняется под шумом (с 25% до 40% и обратно), значит система нестабильна — возможно, углы выбраны неточно или сами источники данных «прыгают».

**Энтропия показывает неопределённость:** Если энтропия умного риска заметно ниже базового — значит, учёт взаимосвязей действительно сделал оценку более определённой и надёжной.

### Бизнес-результат для банка

Вместо отказа 45% клиентов банк теперь может более точно оценивать риски. Клиент Иван Петров, который по простой логике получил бы отказ, теперь может получить кредит под чуть повышенную ставку — банк учёл, что многие подозрения оказались дублями, а живой аналитик их частично развеял.

**Что менять под вашу задачу:**
- `risk_sources` — ваши вероятности рисков
- `angles` — пометьте дубли как `0.0`, компенсирующие как `np.pi`
- Режим склейки: `'weight'` (дефолт), `'norm'` (консервативно), `'quant'` (агрессивно)
---

## Кейс 2: Объединение датчиков

**Задача:** Слить показания нескольких датчиков, учитывая их калибровку, шумы и надёжность.

### Конкретный пример: система пожарной безопасности на заводе

Представьте: завод «Металлург» устанавливает систему раннего обнаружения пожара в цехе покраски. Там работают 3 типа датчиков:

**Дымовой датчик (надёжность 70%):** Старый, но проверенный датчик на потолке. Срабатывает на дым от покрасочных работ, но иногда даёт ложные тревоги от пыли или пара.

**Тепловой датчик (надёжность 65%):** Измеряет температуру воздуха. Надёжен, но реагирует медленно — нагрев заметен только когда огонь уже распространился.

**Датчик угарного газа (надёжность 80%):** Самый современный и точный. Чувствителен к продуктам горения, но дорого стоит — установлен только один на весь цех.

### Проблема калибровки и шумов

**Калибровка:** Дымовой датчик установлен 5 лет назад и постепенно «сдвинулся» — стал более чувствительным к обычной пыли. Тепловой датчик калибровали недавно, он точен. Датчик CO новый, но установлен далеко от рабочих мест.

**Шумы:** В цехе есть вентиляция (размывает показания), покрасочные работы создают «помехи» (пыль, пар), а оборудование вибрирует (может влиять на датчики).

### Почему простое усреднение не работает

Если просто взять среднее от трёх датчиков (70% + 65% + 80%) / 3 = 72%, это не учтёт, что:
- Дымовой датчик «сдвинут» после 5 лет работы
- Тепловой датчик медленнее реагирует, но зато не даёт ложных тревог
- Датчик CO очень точен, но далеко расположен

### Как мы это моделируем

**Углы калибровки:** 
- Дымовой датчик (0.7): угол 0° — считаем базовым
- Тепловой датчик (0.65): угол 30° (π/6) — систематический сдвиг из-за медленной реакции
- Датчик CO (0.8): угол 45° (π/4) — сдвиг из-за удалённого расположения

**Шумы:** Моделируем реальные помехи в цехе — вибрацию оборудования (amp_damp) и турбулентность воздуха от вентиляции (dephase).

### Рецепт (копируйте целиком):

```python
# БЛОК 1: Исходные данные датчиков нашего завода
# [дымовой, тепловой, CO] с учётом особенностей каждого
sensor_probs = [0.7, 0.65, 0.8]           # надёжность каждого типа
sensor_angles = [0.0, np.pi/6, np.pi/4]   # калибровочные сдвиги от завода
print("Датчики:", [(p, f"угол={round(np.degrees(a))}°") for p, a in zip(sensor_probs, sensor_angles)])

# БЛОК 2: Моделируем реальные шумы
sensors = []
for p, angle in zip(sensor_probs, sensor_angles):
    s = PhaseState(p, angle)
    s = amp_damp(s, alpha=0.15)             # затухание сигнала
    s = dephase(s, sigma_phi=0.08)          # фазовый шум
    sensors.append(s)

print("После шума:", [round(s.probability, 3) for s in sensors])

# БЛОК 3: Слияние датчиков
set_phase_or_mode('weight')  # робастный режим
fused = sensors[0]
for sensor in sensors[1:]:
    fused = fused | sensor

print("Объединённый сигнал:", round(fused.probability, 4))

# БЛОК 4: Если много гипотез — используйте регистр
print("\nАнализ гипотез через регистр:")
reg = PhaseRegister.uniform(3)  # 2^3 = 8 гипотез
reg.apply_oracle(lambda x: int(x in [1, 3, 5]))  # отметим некоторые гипотезы
reg.hadamard_all()
best_hypothesis = reg.argmax_probability()
print("Лучшая гипотеза (индекс):", best_hypothesis)
print("Её вероятность:", round(reg.measure_probability(best_hypothesis), 4))
```

### Что получится в результате

**Простое усреднение дало:** 72% надёжности системы. Но это не учитывает особенности каждого датчика.

**Умное объединение покажет:** примерно 75-78% надёжности. Выше, потому что система правильно взвесила каждый датчик с учётом его калибровки и расположения.

**Эффект шумов:** После добавления реальных помех (вибрация, турбулентность) итоговая надёжность может упасть до 70-73%. Это более реалистичная оценка для промышленных условий.

**PhaseRegister для диагностики:** Если используем регистр гипотез, система может определить наиболее вероятную причину тревоги — например, состояние №3 может означать «дым от покрасочных работ, а не пожар» (ложная тревога).

### Практический результат для завода

Система теперь лучше различает реальные пожары от ложных тревог. Например:
- Если срабатывает только дымовой датчик → вероятно, пыль от работ (не эвакуировать людей)
- Если срабатывают дымовой + CO датчик → скорее всего настоящий пожар (немедленная эвакуация)
- Если все три датчика + высокая устойчивость к шумам → 100% пожар (вызывать пожарных)

Завод экономит на ложных эвакуациях (они стоят ~50 тыс. руб. каждая из-за остановки производства), но при этом не пропускает настоящие пожары.

**Что менять под вашу задачу:**
- `sensor_probs` — доверие к каждому датчику
- `sensor_angles` — калибровочные поправки (если знаете)
- Параметры шума `alpha`, `sigma_phi` — по вашим измерениям
- В `apply_oracle` — логику выбора гипотез
---

## Кейс 3: A/B-тестирование

**Задача:** Сравнить варианты A и B, агрегировать сигналы от разных источников, понять достаточность данных.

### Конкретный пример: интернет-магазин тестирует новую кнопку

Интернет-магазин «Быстрые покупки» тестирует новую кнопку «Купить сейчас» (вариант B) против старой «В корзину» (вариант A). Менеджер получает данные от 4 источников:

**Мобильные пользователи:** A = 12% конверсия, B = 14.5% конверсия. Выборка 5000 человек на каждый вариант.

**Десктопные пользователи:** A = 11% конверсия, B = 13% конверсия. Выборка 3000 человек на каждый вариант.

**Новые клиенты:** A = 12.5% конверсия, B = 12% конверсия. Выборка 2000 человек на каждый вариант.

**Постоянные клиенты:** A = 14% конверсия, B = 16% конверсия. Выборка 4000 человек на каждый вариант.

### Противоречивые сигналы

Видим проблему: одни сегменты показывают преимущество B (мобильные, десктопные, постоянные), а другие — преимущество A (новые клиенты). Простое усреднение даст:
- A: (12% + 11% + 12.5% + 14%) / 4 = 12.4%  
- B: (14.5% + 13% + 12% + 16%) / 4 = 13.9%

Разность +1.5% в пользу B. Но правильно ли это?

### Проблема простого усреднения

Простое усреднение не учитывает:
- **Размеры выборок разные** (от 2000 до 5000 человек)
- **Сегменты ведут себя согласованно или противоречиво**
- **Статистическую значимость** различий в каждом сегменте

Нужен способ правильно взвесить противоречивые сигналы.

### Как мы это моделируем

**Согласованность сегментов:**
- Мобильные (12%→14.5%) и десктопные (11%→13%) — согласованы, оба показывают +2% в пользу B
- Постоянные клиенты (14%→16%) — тоже +2% в пользу B  
- Новые клиенты (12.5%→12%) — противоречат, показывают -0.5% против B

**Углы согласованности:** Первые три сегмента ставим на угол 0° (согласие), новых клиентов — на угол π (противоречие).

### Рецепт (копируйте целиком):

```python
# БЛОК 1: Базовое сравнение A vs B из нашего интернет-магазина
pA, pB = 0.124, 0.139  # общие конверсии (взвешенные по выборкам)
print(f"Конверсия A: {pA}, конверсия B: {pB}")

# Информационные метрики
h_a = shannon_entropy(pA)
h_b = shannon_entropy(pB)
kl_ab = kl_divergence(pA, pB)
kl_ba = kl_divergence(pB, pA)

print(f"Неопределённость A: {round(h_a, 3)}, B: {round(h_b, 3)}")
print(f"Отличие A→B: {round(kl_ab, 3)}, B→A: {round(kl_ba, 3)}")

if max(kl_ab, kl_ba) < 0.01:
    print("⚠️  Различия слабые, нужно больше данных")
else:
    print("✅ Различия заметные")

# БЛОК 2: Агрегация по сегментам нашего интернет-магазина
# [мобильные, десктопные, новые, постоянные] 
channels_A = [0.12, 0.11, 0.125, 0.14]  # конверсии A по сегментам
channels_B = [0.145, 0.13, 0.12, 0.16]  # конверсии B по сегментам

# Согласованность сегментов по логике бизнеса:
# Мобильные, десктопные, постоянные — все показывают +B (согласованы)
# Новые клиенты — показывают +A (противоречат)
angles_A = [0.0, 0.0, 0.0, np.pi]  # новые клиенты противоречат тренду
angles_B = [0.0, 0.0, 0.0, np.pi]  # та же логика для B

def aggregate_channels(probs, angles, label):
    set_phase_or_mode('norm')  # консервативно для A/B
    states = [PhaseState(p, a) for p, a in zip(probs, angles)]
    result = states[0]
    for state in states[1:]:
        result = result | state
    print(f"Агрегированный {label}: {round(result.probability, 4)}")
    return result

agg_A = aggregate_channels(channels_A, angles_A, "A")
agg_B = aggregate_channels(channels_B, angles_B, "B")

# БЛОК 3: Устойчивость под шумом
print("\nПроверка устойчивости:")
for noise_level in [0.05, 0.15, 0.25]:
    a_noisy = dephase(agg_A, sigma_phi=noise_level)
    b_noisy = dephase(agg_B, sigma_phi=noise_level)
    diff = abs(a_noisy.probability - b_noisy.probability)
    print(f"Шум {noise_level}: разность A-B = {round(diff, 4)}")
```

### Что получится в результате

**Простое усреднение показало:** A = 12.4%, B = 13.9%, разность +1.5% в пользу B.

**Умная агрегация покажет:** A ≈ 12.2%, B ≈ 13.7%, разность +1.5% в пользу B, НО с поправкой на противоречивые сигналы. Система покажет, что эффект в основном идёт от мобильных и постоянных клиентов, а новые клиенты ведут себя по-другому.

**Проверка статистической значимости:** KL-дивергенция покажет, достаточно ли различий для принятия решения. Если KL > 0.01, различия статистически значимы.

**Анализ устойчивости:** Если под разными уровнями шума разность A-B остаётся стабильной (~1.5%), то результат надёжен. Если «прыгает» от 0.5% до 3%, то данных пока недостаточно.

### Бизнес-решение для интернет-магазина

**Вывод:** Новая кнопка B действительно лучше, но **только для определённых сегментов**:
- ✅ Внедрить кнопку «Купить сейчас» для мобильных и постоянных клиентов  
- ❌ Оставить кнопку «В корзину» для новых клиентов (они привыкли к стандартному процессу)
- 📊 Собрать больше данных по десктопным пользователям (выборка была меньше)

**Экономический эффект:** Если у магазина 100,000 клиентов в месяц, то правильная сегментация даст +1,500 дополнительных покупок в месяц. При средней марже 500₽ это +750,000₽ дохода в месяц просто от правильного анализа A/B-теста!

**Что менять под вашу задачу:**
- `pA`, `pB` — ваши базовые конверсии
- `channels_A`, `channels_B` — оценки от разных источников
- `angles_A`, `angles_B` — согласованность источников (0 = вместе, π = против)
- Пороги для "слабых различий" в KL
---

## Быстрые советы по выбору режимов

**Режимы склейки (set_phase_or_mode):**
- `'weight'` — начните с этого, робастный компромисс
- `'norm'` — когда нужна гарантия p ∈ [0,1] при многих источниках
- `'quant'` — для исследований, показывает "потенциал усиления"
- `'opt'` — теоретическая согласованность уровней 3↔4

**Углы согласованности:**
- `0.0` — источники дублируют/усиливают друг друга
- `np.pi` — источники компенсируют/противоречат
- `np.pi/2` — частичный конфликт
- Если не уверены — начните с `0.0` и `np.pi`

**Параметры шума:**
- `sigma_phi=0.05-0.2` — фазовая нестабильность
- `alpha=0.1-0.3` — затухание амплитуды
- Больше значения = больше шума
---

## Что дальше

1. **Скопируйте нужный блок** под вашу задачу
2. **Подставьте свои числа** в помеченные места
3. **Проверьте результат** на вашем тестовом наборе
4. **Настройте углы и режим** по валидации
5. **Добавьте мониторинг** устойчивости к шуму

Если что-то не работает — сначала проверьте импорты и установку matplotlib, потом экспериментируйте с режимами и углами.
#### A/B‑анализ и принятие решений
Задача: оценить, насколько A отличается от B, и сколько данных нужно. Часто источников несколько (каналы, сегменты, модели), и их вклад противоречив.
Как делать:
1) На уровне 2 посчитайте H₂(p) — мера неопределённости варианта — и KL(pA||pB) (и наоборот) — насколько A не похоже на B. Если KL малая — отличия слабые, нужен больший объём.
2) При агрегировании многих источников, приводящих pA/pB, можно перейти на уровень 4 и отразить противоречия фазами: согласованные каналы — близкие φ, конфликтующие — φ≈π; режим ‘norm’/‘weight’ для безопасности.
3) Если различия нестабильны — добавьте шумы и проверьте, насколько меняется итог (устойчив ли вывод).
Что это даёт аналитику:
Базовая статистика (H₂, KL) + инструмент осмысленного объединения сигналов (⊕₄) при сложных контурах данных.
Уменьшение “переучёта” при дублях и прозрачная политика в конфликтных данных (когда одни каналы “за”, другие “против”).
### Как выбирать «углы согласованности» (фазы) и режим — практические подсказки
Если нет доменной экспертизы по фазам, начните с простого: φ=0 (согласие), φ=π (конфликт). Это уже даёт пользу: дубли не гиперусиливаются, контр‑сигналы компенсируются.
Постепенно уточняйте φ по валидации/метрикам (например, по стабильности итогового P под шумом или по точности на ретроспективе).
Режим ⊕₄:
Начальный продакшен — ‘weight’: как правило, даёт хорошее соотношение “усиливает согласованное, но не срывает крышу”.
Строгий контроль — ‘norm’: полезно при длинных пайплайнах/регуляторике.
Исследования — ‘quant’: увидеть потенциал “верхнего предела”.
Теоретическая согласованность 3↔4 — ‘opt’ (Δφ=π/2).
Особая логика? ‘custom’: впишите собственное правило сочетания p и φ.
### Проверка и верификация (чтобы не обмануть себя)
Держите рядом метрики: H₂/H₃/H₄ для итогового состояния, KL для сравнения сценариев, когерентность (L4).
Прогоняйте “шумовые прогоны” (σφ, α) — если вывод сильно меняется, либо переоценили согласованность, либо режим слишком агрессивен.
Смотрите потери информации при проекциях (4→3→2): вы явно видите, что теряется при упрощении — это полезно и для документации, и для аудита.
### Ограничения и честные оговорки
Это не универсальный квантовый симулятор; тензорная структура уровня 4 здесь приближённая, без полноценной запутанности и унитарных цепочек уровня QSDK.
Непрерывные энтропии считаются численно; точность зависит от сетки и параметров интегрирования.
Фазы — это модель. Их нужно выбирать осмысленно и проверять валидацией.
### С чего начать (быстрый план внедрения)
Спринт 1 (неделя):
Привести 3–5 источников в L2, получить базовый “p(any)” и H₂.
Добавить L4 для двух очевидных “дублей/контр‑сигналов”: φ=0/π, режим ‘weight’.
Сравнить результат и стабильность под σφ∈{0.05,0.2}, α∈{0.1,0.3}.
Спринт 2:
Точнее подобрать φ на ретроспективе, включить ещё 2–3 источника, где есть конфликт.
Добавить отчёт о потерях информации при проекциях (4→3→2), формально описать политику ⊕₄.
Спринт 3:
Если гипотез много — задействовать PhaseRegister для ускоренного перебора/оценки, добавить POVM‑критерий.
Закрепить практики: “когда ‘norm’/‘weight’/‘quant’”, чек‑лист по шумам, мониторинг когерентности.
### Итог
Библиотека полезна, потому что делает сложные вопросы слияния вероятностей управляемыми: есть фазы (согласованность), режимы ⊕₄ (политика), шумы (устойчивость), энтропии и KL (диагностика), и простые интерфейсы (L2→L3→L4).
Она “приземляет” абстрактные идеи интерференции к очень практичным задачам: риски, сенсоры, A/B — там, где нужно не только “сложить вероятности”, но и осмысленно учесть зависимость, дубли и конфликты.